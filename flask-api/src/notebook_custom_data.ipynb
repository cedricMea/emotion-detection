{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/cedric/Workspace/Workspace_Python/kaggle/emotion-detection/flask-api/src/../', '', '/home/cedric/CLUSTER/anaconda3/envs/my_env/lib/python36.zip', '/home/cedric/CLUSTER/anaconda3/envs/my_env/lib/python3.6', '/home/cedric/CLUSTER/anaconda3/envs/my_env/lib/python3.6/lib-dynload', '/home/cedric/CLUSTER/anaconda3/envs/my_env/lib/python3.6/site-packages', '/home/cedric/CLUSTER/anaconda3/envs/my_env/lib/python3.6/site-packages/IPython/extensions', '/home/cedric/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.path.abspath('') \n",
    "root_dir = os.path.join(current_dir, \"../\")\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "print(sys.path)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import string\n",
    "\n",
    "import utils, config \n",
    "from engine import engine_lr, engine_nn\n",
    "from processing import processing, emb_processing\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Dense, Flatten\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadness_data = pd.read_csv(\"../inputs/edited_data/new_sadness.csv\")\n",
    "joy_data = pd.read_csv(\"../inputs/edited_data/new_joy.csv\")\n",
    "anger_data = pd.read_csv(\"../inputs/edited_data/new_anger.csv\")\n",
    "love_data = pd.read_csv(\"../inputs/edited_data/new_love.csv\")\n",
    "\n",
    "data = pd.concat([sadness_data, joy_data, love_data, anger_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentiment\"] = data[\"sentiment\"].apply(lambda x: str(x).strip())\n",
    "data[\"sentiment\"] = data[\"sentiment\"].apply(lambda x: \"anger\" if x==\"hate\" else x)\n",
    "\n",
    "data = data[data.sentiment.isin([\"sadness\", \"anger\", \"joy\", \"love\"])] \n",
    "\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: utils.clean_tweets(x))\n",
    "\n",
    "data_merge = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Devide data set between train and test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    data_merge.drop(config.TARGET_COL, axis=1),\n",
    "    data_merge[config.TARGET_COL],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=data_merge[config.TARGET_COL].values\n",
    ")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "y_val_encoded = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness    643\n",
       "anger      569\n",
       "joy        415\n",
       "love       349\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'joy', 'love', 'sadness'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {\n",
    "    0: 643/569,\n",
    "    1: 643/415,\n",
    "    2: 643/349,\n",
    "    3: 643/643\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN + embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = data_merge.sample(frac=1)\n",
    "\n",
    "#x_clean = preprocess_func.transform(X)\n",
    "x_clean = emb_processing.clean_text(X_train)\n",
    "x_input, tokenizer = emb_processing.tokenize_text(x_clean, istraining=True)\n",
    "\n",
    "x_test_clean = emb_processing.clean_text(X_test)\n",
    "x_test_input, _ = emb_processing.tokenize_text(x_test_clean, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_labels = keras.utils.to_categorical(y_encoded)\n",
    "\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_test_labels = keras.utils.to_categorical(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328     i love it when i feel hot and beautiful and sexy\n",
       "143    i know it be the holy spirit at work plus it f...\n",
       "290                  i be feel frustrated and tire today\n",
       "537    i be not amazing or great at photography but i...\n",
       "433            i be feel a combination of smug and happy\n",
       "513    i can not help but feel proud and grateful to ...\n",
       "250       i feel so honor to have be a part of this year\n",
       "131    oh thunderstorm boo why do they always have to...\n",
       "51     id just have a terrible nightmare and be feel ...\n",
       "561    i come to this realization that i be often fee...\n",
       "381    where be the good music and lyric it seem like...\n",
       "426    i want to scream to yell at everyone who i fee...\n",
       "197    i feel horrible because i feel horrible make w...\n",
       "306    i wish she know what she put me through she st...\n",
       "560    i be feel melancholy i will embrace it and lis...\n",
       "214    i feel thrill to be able to investigate my own...\n",
       "404                                          i suck dick\n",
       "580       people fall in love very quickly for this girl\n",
       "99             i be feel my way through and trust myself\n",
       "19     i have this feeling that if i have anymore vig...\n",
       "495    when i saw a man hit a child of year without a...\n",
       "529    i be sick of you feel sad and upset so let do ...\n",
       "136    i be try to focus on not feel sorry for myself...\n",
       "497    i no raphael say grasp for his usual eloquence...\n",
       "218                              i do not feel that long\n",
       "13     i drive dannika to school i be feel a little b...\n",
       "249    i have realize that by ignore it i be no bette...\n",
       "71        she be wonderful do not get to meet her though\n",
       "389    i feel like i be go to break at any second and...\n",
       "218          so thing do not work out a expect well damm\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clean.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, word_emb = emb_processing.read_embedded_vecs(config.EMBEDDING_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "limite_apparition = 2\n",
    "from collections import Counter\n",
    "results = Counter()\n",
    "x_clean.str.split().apply(results.update)\n",
    "results = results.most_common()\n",
    "reccurent_words = [tuple[0] for tuple in results if (tuple[1]>= limite_apparition) and (tuple[0] not in word_emb.keys())]\n",
    "#print([tuple for tuple in results if tuple[0] not in word_emb.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['siwons', 'anyones', 'bummin']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reccurent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = emb_processing.get_embedding_matrix(word_emb, tokenizer, reccurent_words=reccurent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50/50 - 2s - loss: 1.7606 - mcc_metric: 0.0533 - acc: 0.2873 - val_loss: 1.3067 - val_mcc_metric: 0.1806 - val_acc: 0.3838\n",
      "Epoch 2/15\n",
      "50/50 - 1s - loss: 1.5667 - mcc_metric: 0.2072 - acc: 0.4032 - val_loss: 1.1222 - val_mcc_metric: 0.2350 - val_acc: 0.4268\n",
      "Epoch 3/15\n",
      "50/50 - 1s - loss: 1.4584 - mcc_metric: 0.2600 - acc: 0.4443 - val_loss: 1.0861 - val_mcc_metric: 0.2489 - val_acc: 0.4419\n",
      "Epoch 4/15\n",
      "50/50 - 1s - loss: 1.3593 - mcc_metric: 0.3239 - acc: 0.4949 - val_loss: 1.0662 - val_mcc_metric: 0.2831 - val_acc: 0.4646\n",
      "Epoch 5/15\n",
      "50/50 - 1s - loss: 1.1983 - mcc_metric: 0.4328 - acc: 0.5734 - val_loss: 0.9470 - val_mcc_metric: 0.4786 - val_acc: 0.6061\n",
      "Epoch 6/15\n",
      "50/50 - 1s - loss: 1.0988 - mcc_metric: 0.5131 - acc: 0.6354 - val_loss: 0.8575 - val_mcc_metric: 0.5449 - val_acc: 0.6540\n",
      "Epoch 7/15\n",
      "50/50 - 1s - loss: 0.9756 - mcc_metric: 0.6175 - acc: 0.7127 - val_loss: 0.8371 - val_mcc_metric: 0.5438 - val_acc: 0.6616\n",
      "Epoch 8/15\n",
      "50/50 - 2s - loss: 0.8378 - mcc_metric: 0.6606 - acc: 0.7443 - val_loss: 0.8168 - val_mcc_metric: 0.5951 - val_acc: 0.6894\n",
      "Epoch 9/15\n",
      "50/50 - 1s - loss: 0.7452 - mcc_metric: 0.6989 - acc: 0.7734 - val_loss: 0.8536 - val_mcc_metric: 0.6047 - val_acc: 0.6970\n",
      "Epoch 10/15\n",
      "50/50 - 2s - loss: 0.6571 - mcc_metric: 0.7392 - acc: 0.8051 - val_loss: 0.8274 - val_mcc_metric: 0.5844 - val_acc: 0.6894\n",
      "Epoch 11/15\n",
      "50/50 - 2s - loss: 0.6302 - mcc_metric: 0.7539 - acc: 0.8152 - val_loss: 0.9731 - val_mcc_metric: 0.5887 - val_acc: 0.6843\n",
      "Epoch 12/15\n",
      "50/50 - 2s - loss: 0.6011 - mcc_metric: 0.7464 - acc: 0.8095 - val_loss: 0.8554 - val_mcc_metric: 0.6165 - val_acc: 0.7020\n",
      "Epoch 13/15\n",
      "50/50 - 2s - loss: 0.4854 - mcc_metric: 0.8025 - acc: 0.8532 - val_loss: 1.1211 - val_mcc_metric: 0.5673 - val_acc: 0.6717\n",
      "Epoch 14/15\n",
      "50/50 - 2s - loss: 0.4359 - mcc_metric: 0.8378 - acc: 0.8778 - val_loss: 0.9887 - val_mcc_metric: 0.6538 - val_acc: 0.7273\n",
      "Epoch 15/15\n",
      "50/50 - 2s - loss: 0.3348 - mcc_metric: 0.8742 - acc: 0.9044 - val_loss: 0.9673 - val_mcc_metric: 0.6368 - val_acc: 0.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf62334eb8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_addons.metrics import MatthewsCorrelationCoefficient\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "n_classes = 4\n",
    "epochs = 15\n",
    "model_1 = engine_nn.FeedForwardNn(embedding_matrix=emb_matrix, n_classes=n_classes)\n",
    "model_2 = engine_nn.LstmNetwork(embedding_matrix=emb_matrix, n_classes=n_classes)\n",
    "model_3 = engine_nn.MixNetwork(embedding_matrix=emb_matrix, n_classes=n_classes)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
    "model_1.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=[utils.mcc_metric, \"acc\"])\n",
    "model_2.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=[utils.mcc_metric, \"acc\"])\n",
    "model_3.compile(loss='categorical_crossentropy',optimizer=opt, metrics=[utils.mcc_metric, \"acc\"])\n",
    "\n",
    "#model_1.fit(x=x_input, y=y_labels, verbose=2, validation_data=(x_test_input, y_test_labels), epochs=epochs, class_weight=class_weight)\n",
    "#model_2.fit(x=x_input, y=y_labels, verbose=2, validation_data=(x_test_input, y_test_labels), epochs=epochs, class_weight=class_weight)\n",
    "model_3.fit(x=x_input, y=y_labels, verbose=2, validation_data=(x_test_input, y_test_labels), epochs=epochs, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 1.4859 - mcc_metric: 0.4679 - acc: 0.5934\n",
      "[1.4858554601669312, 0.4679487347602844, 0.5934343338012695]\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.8142 - mcc_metric: 0.4423 - acc: 0.5859\n",
      "[1.8141738176345825, 0.4423076808452606, 0.5858585834503174]\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9414 - mcc_metric: 0.5705 - acc: 0.6742\n",
      "[0.941415548324585, 0.5705128312110901, 0.6742424368858337]\n"
     ]
    }
   ],
   "source": [
    "print(model_1.evaluate(x_test_input, y_test_labels))\n",
    "print(model_2.evaluate(x_test_input, y_test_labels))\n",
    "print(model_3.evaluate(x_test_input, y_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_input)\n",
    "\n",
    "winning_class = np.apply_along_axis(lambda x: np.argmax(x), 1, predictions)\n",
    "winning_class_pred = np.apply_along_axis(lambda x: np.max(x), 1, predictions)\n",
    "winning_class_name = label_encoder.inverse_transform(winning_class)\n",
    "\n",
    "train_copie = X_train.copy()\n",
    "train_copie[\"clean\"] = x_clean.values\n",
    "train_copie[\"value\"] = y_train.values\n",
    "train_copie[\"pred\"] = winning_class_name\n",
    "train_copie[\"pred_prop\"] = winning_class_pred\n",
    "\n",
    "train_copie[\"match\"] = train_copie.apply(lambda x: int(x.value==x.pred), axis=1)\n",
    "train_copie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_copie[train_copie.match==1].value.value_counts())\n",
    "print(train_copie[train_copie.match==0].value.value_counts())\n",
    "pd.crosstab(train_copie.value, train_copie.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results on raw exmple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    like\n",
      "Name: text, dtype: object\n",
      "[[0.22524747 0.28871542 0.17468892 0.31134823]]\n",
      "['anger' 'joy' 'love' 'sadness']\n"
     ]
    }
   ],
   "source": [
    "sentence_test = \"like \"\n",
    "\n",
    "test_clean = emb_processing.clean_text(pd.DataFrame({config.TEXT_COL:[sentence_test]}))\n",
    "print(test_clean)\n",
    "x_test, _ = emb_processing.tokenize_text(test_clean, istraining=False, tokenizer=tokenizer)\n",
    "\n",
    "print(model_3.predict(x_test))\n",
    "\n",
    "print(label_encoder.inverse_transform([0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/cedric/Workspace/Workspace_Python/kaggle/emotion-detection/flask-api/src/../models/custom_data/custom_data_model/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Create the directory for the model\n",
    "Path(config.CUSTOM_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "model_to_keep = model_3\n",
    "\n",
    "\n",
    "label_dict = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "\n",
    "\n",
    "pickle.dump(label_dict, open(config.CUSTOM_DATA_LABEL_DICT_PATH, \"wb\"))\n",
    "pickle.dump(tokenizer, open(config.CUSTOM_DATA_TOKENIZER_PATH, \"wb\"))\n",
    "tf.keras.models.save_model(\n",
    "    model_to_keep, config.CUSTOM_DATA_MODEL_PATH, overwrite=True, include_optimizer=True, save_format=\"tf\",\n",
    "    signatures=None, options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_env]",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
